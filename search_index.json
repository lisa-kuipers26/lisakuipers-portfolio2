[["index.html", "Portofolio workflows 1 Introductie", " Portofolio workflows Lisa Kuipers 2022-05-09 1 Introductie "],["c.-elegans-plate-experiment.html", "2 C. elegans plate experiment", " 2 C. elegans plate experiment tabel &lt;- read_excel(here::here(&quot;data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) tabel$compConcentration &lt;- as.double(tabel$compConcentration) tabel$compName &lt;- as.factor(tabel$compName) #x-as concentreatie in -10log tabel$compConcentration &lt;- ifelse(tabel$compConcentration==0,0,-log10(tabel$compConcentration)) tabel %&gt;% ggplot(aes(x=compConcentration,y=RawData,color=compName,shape=expType))+ geom_jitter(width=0.1)+ labs(x=&quot;Concentratie (-log10) &quot;, y=&quot;Number of offspring&quot;) De compConcentration was eerst het type character waardoor de labels niet op schaal lagen. Door het te veranderen naar het type van een double kan er een schaal gemaakt worden. De positieve controle van dit experiment is ethanol . De negatieve controle van dit experiment is de S-medium Experimentele opzet: 1. Data plotten zodat er een globaal overzicht hebt 2. #Genormalizeerd en gemiddelde naar 1 neg_controle &lt;- tabel %&gt;% filter(expType==&quot;controlNegative&quot;) tabel$RawData[tabel$expType == &#39;controlNegative&#39;] &lt;- neg_controle$RawData / mean(neg_controle$RawData) tabel %&gt;% ggplot(aes(x=compConcentration,y=RawData,color=compName,shape=expType))+ geom_jitter(width=0.1)+ labs(x=&quot;Concentratie (-log10) &quot;, y=&quot;Number of offspring&quot;) "],["open-peer-review.html", "3 Open Peer Review 3.1 Onderzoek op reproduceerbaarheid beoordelen 3.2 Code zelf reproduceren", " 3 Open Peer Review 3.1 Onderzoek op reproduceerbaarheid beoordelen In dit gedeelte wordt een artikel beoordeeld op de reproduceerbaarheid. Deze wordt beoordeeld aan de hand van een verschillende criteria omschreven in de onderstaande tabel. Voor de beoordeling is een artikel gekozen primair onderzoek dat beschikbaar is op PMC. Gebruikte artikel: Amawi KF, Alkhatib AJ. Urtica Pilulifera in Treating Pre-diabetic Rat Model to Control the Blood Glucose, Lipids and Oxidative Stress. Med Arch. 2020;74(3):168-171. doi:10.5455/medarh.2020.74.168-171 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7405998/ 3.1.1 Omschrijving onderzoek Het doel van dit onderzoek is kijken of Urtica pilulifera (een plant) effect heeft op pre-diabetische ratten en ook de antioxiderende werking onderzoeken De ratten werden ingedeeld in drie groepen van 10; een controle groep, een pre diabetische groep, en een groep met de behandeling van U. pilulifera. De ratten pre-diabetisch gemaakt kregen een hoog sucrose dieet, de controle groep een normaal dieet en de behandelde groep kreeg hetzelfde dieet als de pre-diabetische ratten met U. pilulifera extract geïnjecteerd. Na 30 dagen werden bloed samples afgenomen en getest op glucose, triglycerides, cholesterol, GSH, TAC en MDA Uit het onderoek bleek dat glucose, triglyceride en MDA niveaus in de pre-diabetic groep significant verhoogd waren en significant verlaagd in de U. pilulifera groep. GSH en TAC was significant hoger in de U. pilulifera ten opzichte van de pre-diabetische groep. Er zat geen significant verschil in cholesterol niveau in de groepen. 3.1.2 Beoordeling artikel In de tabel staat of het artikel aan de verschillende criterium voldoet. Criteria Answer Study purpose Yes Data availability No Data location Data location not stated Study location Yes Author review Author listed but did not fill out contact Ethics statement No Funding statement Yes Code availability No Het blijkt dat het artikel maar aan drie van acht criteria voldoet. Hoewel het artikel goed te lezen was is deze dus toch niet goed reproduceerbaar. 3.2 Code zelf reproduceren Net is er gekeken reporduceerbaarheid van een primair onderzoek. In dit onderdeel wordt er gekeken naar de reporduceerbaarheid van (R) code. Data en code van onderstaand onderzoek gebruikt: Strozza C, Myrskylä M. Monitoring trends and differences in COVID-19 case-fatality rates using decomposition methods: Contributions of age structure and age-specific fatality. PLoS One. 2020 Sep 10;15(9):e0238904. doi: 10.1371/journal.pone.0238904. PMID: 32913365; PMCID: PMC7482960. https://pubmed.ncbi.nlm.nih.gov/32913365/ Link naar de code: https://osf.io/g7vjd/ 3.2.1 Beoordeling script Het script zelf was goed te lezen. Er waren 4 scripts die elkaar opvolgde, door de getallen in de bestandsnaam was het makkelijk te zien welke als eerst uitgevoerd moest worden. In de scripts zelf stonden genoeg comments om te begrijpen waar elk stuk code voor diende en ziet de code zelf er netjes uit. Ik geef de leesbaarheid dus ook een 5/5 De code was ook goed reproduceerbaar. Er was alleen één probleem wat handmatig opgelost moest worden, dit probleem en hoe deze opgelost is staat beschreven hieronder. Hierdoor krijgt de reproduceerbaarheid een 4/5, want nadat dit probleem opgelost was, konden alle tabellen makkelijk gemaakt worden. 3.2.2 Probleem in script ### Monitoring trends and differences in COVID-19 case fatality ############## ### rates using decomposition methods: A demographic perspective ############## ### Last updated: 2020-07-16 09:27:20 CEST ### Contact: ### riffe@demogr.mpg.de ### acosta@demogr.mpg.de ### dudel@demogr.mpg.de ### Get data ################################################################## # Required packages source((&quot;R/00_functions.R&quot;)) # URL + filename url &lt;- &#39;https://osf.io/wu5ve//?action=download&#39; filename &lt;- &#39;Data/Output_10.csv&#39; # Load data GET(url, write_disk(filename, overwrite = TRUE)) dat &lt;- read_csv(filename,skip=3) Bij het uitvoeren van de code hierboven kwam de onderstaande foutmelding: In de foutmelding is html te zien. Dit hoort natuurlijk niet bij een read_csv() functie. In de code wordt het bestand van een online directory gedownload. De URL staat in de code en wanneer deze bezocht werd stond er dit bericht: Het bestand bevindt zich niet meer op de plek waar de URL naar verwees en kon dus ook niet gedownload worden waardoor de html van de pagina werd overgenomen. Er was echter wel een menu aan de zijkant aanwezig waar het mogelijk is om bij de github van het project te komen. Hier vond ik het output bestand wat nodig is voor de code en heb deze handmatig gedownload en toegevoegd aan de /Data directory. Nadat deze in de directory stond kon het script en de rest van de scripts vlekkeloos uitgevoerd worden.Hieronder staan alle scripts met de aanpassing in het tweede script. ### Monitoring trends and differences in COVID-19 case fatality ############## ### rates using decomposition methods: A demographic perspective ############## ### Last updated: 2020-07-14 11:19:20 CEST ### Contact: ### riffe@demogr.mpg.de ### acosta@demogr.mpg.de ### dudel@demogr.mpg.de ### Load packages ############################################################# library(tidyverse) library(data.table) library(writexl) library(httr) ### Case fatality rate ####################################################### # cc = case-age distribution # rr = age-specific case fatality rates cfr &lt;- function(cc,rr){ sum(cc * rr) } ### Kitagawa decomposition #################################################### # c1 = Age distribution population 1 # r1 = Case fatality rates population 1 # c2 = Age distribution population 2 # r2 = Case fatality rates population 2 kitagawa_cfr &lt;- function(c1, r1, c2, r2){ # Calculate age-distribution of cases c1 &lt;- c1 / sum(c1) c2 &lt;- c2 / sum(c2) # Total difference Tot &lt;- cfr(c1, r1) - cfr(c2, r2) # Age component Aa &lt;- sum((c1 - c2) * (r1 + r2) / 2) # Case fatality component Bb &lt;- sum((r1 - r2) * (c1 + c2) / 2) # Output list(Diff = Tot, AgeComp = Aa, RateComp = Bb, CFR1 = weighted.mean(r1,c1), CFR2 = weighted.mean(r2,c2)) } ### Monitoring trends and differences in COVID-19 case fatality ############## ### rates using decomposition methods: A demographic perspective ############## ### Last updated: 2020-07-16 09:27:20 CEST ### Contact: ### riffe@demogr.mpg.de ### acosta@demogr.mpg.de ### dudel@demogr.mpg.de ### Get data ################################################################## # Required packages source((&quot;R/00_functions.R&quot;)) # URL + filename filename &lt;- &#39;Data/Output_10.csv&#39; # Load data dat &lt;- read_csv(filename,skip=3) ### Edit data (select countries, etc.) ######################################## # Lists of countries and regions countrylist &lt;- c(&quot;China&quot;,&quot;Germany&quot;,&quot;Italy&quot;,&quot;South Korea&quot;,&quot;Spain&quot;,&quot;USA&quot;) region &lt;- c(&quot;All&quot;,&quot;NYC&quot;) # Restrict dat &lt;- dat %&gt;% filter(Country %in% countrylist &amp; Region %in% region) # Remove Tests variable dat &lt;- dat %&gt;% mutate(Tests=NULL) # Drop if no cases/Deaths dat &lt;- na.omit(dat) ### Save ###################################################################### write_csv(dat,file=&quot;Data/inputdata.csv&quot;) ### Monitoring trends and differences in COVID-19 case fatality ############## ### rates using decomposition methods: A demographic perspective ############## ### Last updated: 2020-07-14 11:19:20 CEST ### Contact: ### riffe@demogr.mpg.de ### acosta@demogr.mpg.de ### dudel@demogr.mpg.de ### Load functions &amp; packages ################################################# source((&quot;R/00_functions.R&quot;)) ### Load and edit data ######################################################## # Load CSV file dat &lt;- read_csv(&quot;Data/inputdata.csv&quot;) # Set Date as date dat$Date &lt;- as.Date(dat$Date,&quot;%d.%m.%y&quot;) # Find max dates maxdates &lt;- dat %&gt;% group_by(Country,Region) %&gt;% summarize(maxdate=max(Date)) # Get least common denominator maxdate &lt;- maxdates %&gt;% filter(Country!=&quot;China&quot;) %&gt;% ungroup() %&gt;% summarize(min(maxdate)) # As vector maxdate &lt;- as.data.frame(maxdate)[1,1] ### Numbers for Table 1 ####################################################### # Latest date: maxdate refdate &lt;- as.Date(&quot;30.06.2020&quot;,&quot;%d.%m.%Y&quot;) dat2 &lt;- dat %&gt;% filter(Date&lt;=refdate) #maxdate # Aggregate case and death counts cases &lt;- aggregate(Cases~Code+Date+Country+Region,data=dat2[dat2$Sex==&quot;b&quot;,],sum) deaths &lt;- aggregate(Deaths~Code+Date+Country+Region,data=dat2[dat2$Sex==&quot;b&quot;,],sum) # Most recent counts cases %&gt;% group_by(Country,Region) %&gt;% slice(which.max(Date)) deaths %&gt;% group_by(Country,Region) %&gt;% slice(which.max(Date)) ### Analysis for Table 2 (and appendix) ####################################### # Calculate ASFRs dat &lt;- dat %&gt;% mutate(ascfr = Deaths / Cases, ascfr = replace_na(ascfr, 0)) # Get codes for reference countries maxdate &lt;- format.Date(maxdate,&quot;%d.%m.%Y&quot;) refdate &lt;- as.Date(&quot;30.06.2020&quot;,&quot;%d.%m.%Y&quot;) refdate2 &lt;- format.Date(refdate,&quot;%d.%m.%Y&quot;)#maxdate DE_code &lt;- paste0(&quot;DE_&quot;,refdate2)#paste0(&quot;DE_&quot;,maxdate) IT_code &lt;- paste0(&quot;ITbol&quot;,refdate2)#paste0(&quot;ITinfo&quot;,maxdate) SK_code &lt;- paste0(&quot;KR&quot;,refdate2)#paste0(&quot;SK&quot;,maxdate) # Decide some reference patterns (For main text: SK) DE &lt;- dat %&gt;% filter(Code == DE_code, Sex == &quot;b&quot;) IT &lt;- dat %&gt;% filter(Code == IT_code, Sex == &quot;b&quot;) SK &lt;- dat %&gt;% filter(Code == SK_code, Sex == &quot;b&quot;) # Decompose DecDE &lt;- as.data.table(dat)[, kitagawa_cfr(DE$Cases, DE$ascfr,Cases,ascfr), by=list(Country, Code, Date, Sex, Region)] DecIT &lt;- as.data.table(dat)[, kitagawa_cfr(IT$Cases, IT$ascfr,Cases,ascfr), by=list(Country, Code, Date, Sex,Region)] DecSK &lt;- as.data.table(dat)[, kitagawa_cfr(SK$Cases, SK$ascfr,Cases,ascfr), by=list(Country, Code, Date, Sex,Region)] # Select only most recent date, both genders combined DecDE &lt;- DecDE %&gt;% filter(Sex==&quot;b&quot;) %&gt;% group_by(Country,Region) %&gt;% filter(Date&lt;=refdate) %&gt;% slice(which.max(Date)) DecIT &lt;- DecIT %&gt;% filter(Sex==&quot;b&quot;) %&gt;% group_by(Country,Region) %&gt;% filter(Date&lt;=refdate) %&gt;% slice(which.max(Date)) DecSK &lt;- DecSK %&gt;% filter(Sex==&quot;b&quot;) %&gt;% group_by(Country,Region) %&gt;% filter(Date&lt;=refdate) %&gt;% slice(which.max(Date)) # Drop unnecessary variables DecDE &lt;- DecDE %&gt;% select(Country,Region,Date,CFR2,Diff,AgeComp,RateComp) DecIT &lt;- DecIT %&gt;% select(Country,Region,Date,CFR2,Diff,AgeComp,RateComp) DecSK &lt;- DecSK %&gt;% select(Country,Region,Date,CFR2,Diff,AgeComp,RateComp) # Calculate relative contributions DecDE &lt;- DecDE %&gt;% mutate(relAgeDE = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecDE &lt;- DecDE %&gt;% mutate(relRateDE = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) DecIT &lt;- DecIT %&gt;% mutate(relAgeIT = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecIT &lt;- DecIT %&gt;% mutate(relRateIT = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) DecSK &lt;- DecSK %&gt;% mutate(relAgeSK = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecSK &lt;- DecSK %&gt;% mutate(relRateSK = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) # Rename DecDE &lt;- DecDE %&gt;% rename(DiffDE=Diff,AgeCompDE=AgeComp,RateCompDE=RateComp) DecIT &lt;- DecIT %&gt;% rename(DiffIT=Diff,AgeCompIT=AgeComp,RateCompIT=RateComp) DecSK &lt;- DecSK %&gt;% rename(DiffSK=Diff,AgeCompSK=AgeComp,RateCompSK=RateComp) # Sort data DecDE &lt;- DecDE %&gt;% arrange(CFR2) # Appendix DecIT &lt;- DecIT %&gt;% arrange(CFR2) # Appendix DecSK &lt;- DecSK %&gt;% arrange(CFR2) # Table 2 ### Table 3: Italy trend ###################################################### # Italy trend ITtrend &lt;- dat %&gt;% filter(Code == &quot;ITbol09.03.2020&quot;, Sex == &quot;b&quot;) # Calculate decomposition DecITtrend &lt;- as.data.table(dat)[, kitagawa_cfr(Cases,ascfr,ITtrend$Cases, ITtrend$ascfr), by=list(Country, Code, Date, Sex)] # Select only Italy DecITtrend &lt;- DecITtrend %&gt;% filter(Country==&quot;Italy&quot; &amp; Sex==&quot;b&quot;) # Only keep interesting variables DecITtrend &lt;- DecITtrend %&gt;% select(Country,Code,Date,CFR1,Diff,AgeComp,RateComp) # Relative contributions DecITtrend &lt;- DecITtrend %&gt;% mutate(relAgeDE = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecITtrend &lt;- DecITtrend %&gt;% mutate(relRateDE = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) # Rename DecITtrend &lt;- DecITtrend %&gt;% rename(DiffITt=Diff,AgeCompITt=AgeComp,RateCompITt=RateComp) # Sort data DecITtrend &lt;- DecITtrend %&gt;% arrange(Date) ### Appendix: Trends USA/Spain ################################################ ### NYC trend NYtrend &lt;- dat %&gt;% filter(Code == &quot;US_NYC22.03.2020&quot;, Sex == &quot;b&quot;) # Calculate decomposition DecNYtrend &lt;- as.data.table(dat)[, kitagawa_cfr(Cases,ascfr,NYtrend$Cases, NYtrend$ascfr), by=list(Country, Region,Code, Date, Sex)] # Select only NYC DecNYtrend &lt;- DecNYtrend %&gt;% filter(Country==&quot;USA&quot; &amp; Region==&quot;NYC&quot; &amp; Sex==&quot;b&quot;) # Only keep interesting variables DecNYtrend &lt;- DecNYtrend %&gt;% select(Country,Code,Date,CFR1,Diff,AgeComp,RateComp) # Relative contributions DecNYtrend &lt;- DecNYtrend %&gt;% mutate(relAgeDE = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecNYtrend &lt;- DecNYtrend %&gt;% mutate(relRateDE = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) # Rename DecNYtrend &lt;- DecNYtrend %&gt;% rename(DiffITt=Diff,AgeCompITt=AgeComp,RateCompITt=RateComp) # Sort data DecNYtrend &lt;- DecNYtrend %&gt;% arrange(Date) ### Spain trend EStrend &lt;- dat %&gt;% filter(Code == &quot;ES21.03.2020&quot;, Sex == &quot;b&quot;) # Calculate decomposition DecEStrend &lt;- as.data.table(dat)[, kitagawa_cfr(Cases,ascfr,EStrend$Cases, EStrend$ascfr), by=list(Country, Code, Date, Sex)] # Select only Spain DecEStrend &lt;- DecEStrend %&gt;% filter(Country==&quot;Spain&quot; &amp; Sex==&quot;b&quot;) # Only keep interesting variables DecEStrend &lt;- DecEStrend %&gt;% select(Country,Code,Date,CFR1,Diff,AgeComp,RateComp) # Relative contributions DecEStrend &lt;- DecEStrend %&gt;% mutate(relAgeDE = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecEStrend &lt;- DecEStrend %&gt;% mutate(relRateDE = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) # Rename DecEStrend &lt;- DecEStrend %&gt;% rename(DiffITt=Diff,AgeCompITt=AgeComp,RateCompITt=RateComp) # Sort data DecEStrend &lt;- DecEStrend %&gt;% arrange(Date) ### Germany trend DEtrend &lt;- dat %&gt;% filter(Code == &quot;DE_21.03.2020&quot;, Sex == &quot;b&quot;) # Calculate decomposition DecDEtrend &lt;- as.data.table(dat)[, kitagawa_cfr(Cases,ascfr,DEtrend$Cases, DEtrend$ascfr), by=list(Country, Code, Date, Sex)] # Select only Germany DecDEtrend &lt;- DecDEtrend %&gt;% filter(Country==&quot;Germany&quot; &amp; Sex==&quot;b&quot; &amp; Date&gt;=&quot;2020-03-21&quot;) # Only keep interesting variables DecDEtrend &lt;- DecDEtrend %&gt;% select(Country,Code,Date,CFR1,Diff,AgeComp,RateComp) # Relative contributions DecDEtrend &lt;- DecDEtrend %&gt;% mutate(relAgeDE = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecDEtrend &lt;- DecDEtrend %&gt;% mutate(relRateDE = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) # Rename DecDEtrend &lt;- DecDEtrend %&gt;% rename(DiffITt=Diff,AgeCompITt=AgeComp,RateCompITt=RateComp) # Sort data DecDEtrend &lt;- DecDEtrend %&gt;% arrange(Date) ### Save results ############################################################## # Table 2 write_xlsx(x=DecSK, path=&quot;Output/Table2.xlsx&quot;) # Table 3 write_xlsx(x=DecITtrend, path=&quot;Output/Table3.xlsx&quot;) # Appendix table 1 write_xlsx(x=DecDE, path=&quot;Output/AppendixTab1.xlsx&quot;) # Appendix table 2 write_xlsx(x=DecIT, path=&quot;Output/AppendixTab2.xlsx&quot;) # Appendix table 3 write_xlsx(x=DecNYtrend, path=&quot;Output/AppendixTab3.xlsx&quot;) # Appendix table 4 write_xlsx(x=DecEStrend, path=&quot;Output/AppendixTab4.xlsx&quot;) # Appendix table 5 write_xlsx(x=DecDEtrend, path=&quot;Output/AppendixTab5.xlsx&quot;) ### Monitoring trends and differences in COVID-19 case fatality ############## ### rates using decomposition methods: A demographic perspective ############## ### Last updated: 2020-07-15 16:26:50 CEST ### Contact: ### riffe@demogr.mpg.de ### acosta@demogr.mpg.de ### dudel@demogr.mpg.de ### Load functions &amp; packages ################################################# source((&quot;R/00_functions.R&quot;)) ### Load case data ############################################################ # Load data cases &lt;- read_csv(&quot;Data/inputdata.csv&quot;) # Edit date cases$Date &lt;- as.Date(cases$Date,&quot;%d.%m.%y&quot;) # Lists of countries and regions countrylist &lt;- c(&quot;China&quot;,&quot;Germany&quot;,&quot;Italy&quot;,&quot;South Korea&quot;,&quot;Spain&quot;,&quot;USA&quot;) regionlist &lt;- c(&quot;All&quot;) # Restrict cases &lt;- cases %&gt;% filter(Country %in% countrylist &amp; Region %in% regionlist) # Drop tests cases &lt;- cases %&gt;% mutate(Tests=NULL) ### Load and edit excess mortality data ####################################### # Load CSV file dat &lt;- read_csv(&quot;Data/baseline_excess_pclm_5.csv&quot;) # Set Date as date dat$Date &lt;- as.Date(dat$date,&quot;%d.%m.%y&quot;) # Restrict # Restrict dat &lt;- dat %&gt;% filter(Country %in% countrylist) %&gt;% filter(Date &gt;= &quot;2020-02-24&quot;) ### Analysis similar to Table 2 ############################################### # Generate cumulative excess deaths dat &lt;- dat %&gt;% mutate(exc_p = ifelse(excess &lt; 0, 0, excess)) %&gt;% group_by(Country,Age,Sex) %&gt;% mutate(Exc = cumsum(exc_p)) %&gt;% ungroup() # Edit age variable dat &lt;- dat %&gt;% mutate(Age=recode(Age, &#39;5&#39;=0, &#39;15&#39;=10, &#39;25&#39;=20, &#39;35&#39;=30, &#39;45&#39;=40, &#39;55&#39;=50, &#39;65&#39;=60, &#39;75&#39;=70, &#39;85&#39;=80, &#39;95&#39;=90)) # Aggregate dat &lt;- dat %&gt;% group_by(Country,Sex,Date,Age,Week) %&gt;% select(Exc) %&gt;% summarize_all(sum) # Adjust date for US: case countrs from two days earlier than excess mortality cases$Date[cases$Date==&quot;2020-05-23&quot; &amp; cases$Country==&quot;USA&quot;] &lt;- &quot;2020-05-25&quot; # Merge with cases dat &lt;- inner_join(dat,cases[,c(&quot;Country&quot;,&quot;Date&quot;,&quot;Age&quot;,&quot;Sex&quot;,&quot;Cases&quot;)]) # Calculate ASFRs dat &lt;- dat %&gt;% mutate(ascfr = Exc / Cases, ascfr = replace_na(ascfr, 0), ascfr = ifelse(is.infinite(ascfr),0,ascfr), ascfr = ifelse(ascfr&gt;1,1,ascfr)) # Decide some reference patterns (here Germany) DE &lt;- dat %&gt;% filter(Country == &quot;Germany&quot;, Sex == &quot;b&quot;, #Date == maxdate) Week == 19) # Decompose DecDE &lt;- as.data.table(dat)[, kitagawa_cfr(DE$Cases, DE$ascfr,Cases,ascfr), by=list(Country,Week, Sex)] # Select only most recent date, both genders combined DecDE &lt;- DecDE %&gt;% filter(Sex==&quot;b&quot;) %&gt;% group_by(Country) %&gt;% filter(Week %in% 19:22) # Drop unnecessary variables DecDE &lt;- DecDE %&gt;% select(Country,Week,CFR2,Diff,AgeComp,RateComp) # Calculate relative contributions DecDE &lt;- DecDE %&gt;% mutate(relAgeDE = abs(AgeComp)/(abs(AgeComp)+abs(RateComp))) DecDE &lt;- DecDE %&gt;% mutate(relRateDE = abs(RateComp)/(abs(AgeComp)+abs(RateComp))) # Rename DecDE &lt;- DecDE %&gt;% rename(DiffDE=Diff,AgeCompDE=AgeComp,RateCompDE=RateComp) # Sort data DecDE &lt;- DecDE %&gt;% arrange(CFR2) # Appendix ### Save extra table ########################################################## # Appendix table 1 write_xlsx(x=DecDE, path=&quot;Output/AppendixTab6.xlsx&quot;) ### Monitoring trends and differences in COVID-19 case fatality ############## ### rates using decomposition methods: A demographic perspective ############## ### Last updated: 2020-07-22 11:18:52 CEST ### Contact: ### riffe@demogr.mpg.de ### acosta@demogr.mpg.de ### dudel@demogr.mpg.de ### Packages ################################################################## library(tidyverse) library(ggrepel) library(scales) ### Load data ################################################################# # Load data db_gh &lt;- read_csv(&quot;Data/inputdata.csv&quot;) ### Aggregate data ############################################################ # Filter date db_gh$Date &lt;- as.Date(db_gh$Date,&quot;%d.%m.%y&quot;) db_gh2 &lt;- db_gh %&gt;% filter(Date&lt;=as.Date(&quot;30.06.2020&quot;,&quot;%d.%m.%y&quot;)) # Set New York as &quot;country&quot; (easier handling) db_gh2$Country[db_gh2$Country==&quot;USA&quot; &amp; db_gh2$Region == &quot;NYC&quot;] &lt;- &quot;NYC&quot; # Sum data over age groups db_gh2 &lt;- db_gh2 %&gt;% filter(!Country %in% c(&quot;China&quot;,&quot;USA&quot;,&quot;South Korea&quot;) &amp; Sex == &quot;b&quot;) %&gt;% group_by(Country, Code,Date) %&gt;% summarise(Cases = sum(Cases), Deaths = sum(Deaths)) # Exclude bolletino db_gh2 &lt;- db_gh2 %&gt;% filter(str_sub(Code, 1, 5) != &quot;ITbol&quot;) # Sort by date db_gh2 &lt;- db_gh2 %&gt;% group_by(Country) %&gt;% arrange(Date) # Smooth reporting issues cases for(country in unique(db_gh2$Country)) { days &lt;- db_gh2$Date[db_gh2$Country==country] for(day in 2:length(days)) { current &lt;- db_gh2$Cases[db_gh2$Country==country &amp; db_gh2$Date==days[day]] previous &lt;- db_gh2$Cases[db_gh2$Country==country &amp; db_gh2$Date==days[day-1]] if(current&lt;previous) db_gh2$Cases[db_gh2$Country==country &amp; db_gh2$Date==days[day]] &lt;- previous } } # Smooth reporting issues deaths for(country in unique(db_gh2$Country)) { days &lt;- db_gh2$Date[db_gh2$Country==country] for(day in 2:length(days)) { current &lt;- db_gh2$Deaths[db_gh2$Country==country &amp; db_gh2$Date==days[day]] previous &lt;- db_gh2$Deaths[db_gh2$Country==country &amp; db_gh2$Date==days[day-1]] if(current&lt;previous) db_gh2$Deaths[db_gh2$Country==country &amp; db_gh2$Date==days[day]] &lt;- previous } } ### Plot settings ############################################################# # Set colors col_country &lt;- c(&quot;Germany&quot; = &quot;black&quot;, &quot;Italy&quot; = &quot;#2ca25f&quot;, &quot;NYC&quot;=&quot;#f0027f&quot;, &quot;Spain&quot;=&quot;#beaed4&quot;, &quot;South Korea&quot;=&quot;#fdc086&quot;)#, #&quot;USA&quot;=&quot;#386cb0&quot;) cols &lt;- c(&quot;black&quot;, &quot;#2ca25f&quot;, &quot;#f0027f&quot;, &quot;#beaed4&quot;, &quot;#fdc086&quot;)#, #&quot;#386cb0&quot;) # Axis labs &lt;- db_gh2 %&gt;% group_by(Country) %&gt;% filter(Cases == max(Cases)) %&gt;% mutate(Cases = Cases + 3000) # Including all reports tx &lt;- 6 lim_x &lt;- 240000 ### Plot ###################################################################### db_gh2 %&gt;% ggplot(aes(Cases, Deaths, col = Country))+ geom_line(size = 1, alpha = .9)+ scale_x_continuous(expand = c(0,0), breaks = seq(0, 300000, 50000), limits = c(0, lim_x + 30000), labels = comma)+ scale_y_continuous(expand = c(0,0), breaks = seq(0, 40000, 5000), limits = c(0, 40000), labels = comma)+ annotate(&quot;segment&quot;, x = 0, y = 0, xend = lim_x, yend = lim_x * .02, colour = &quot;grey40&quot;, size = .5, alpha = .3, linetype = 2)+ annotate(&quot;segment&quot;, x = 0, y = 0, xend = lim_x, yend = lim_x * .05, colour = &quot;grey40&quot;, size = .5, alpha = .3, linetype = 2)+ annotate(&quot;segment&quot;, x = 0, y = 0, xend = lim_x, yend = lim_x * .10, colour = &quot;grey40&quot;, size = .5, alpha = .3, linetype = 2)+ annotate(&quot;segment&quot;, x = 0, y = 0, xend = lim_x, yend = lim_x * .15, colour = &quot;grey40&quot;, size = .5, alpha = .3, linetype = 2)+ annotate(&quot;text&quot;, label = &quot;2% CFR&quot;, x = lim_x + 1000, y = lim_x * .02, color=&quot;grey30&quot;, size = tx * .3, alpha = .6, hjust = 0, lineheight = .8) + annotate(&quot;text&quot;, label = &quot;5% CFR&quot;, x = lim_x + 1000, y = lim_x * .05, color=&quot;grey30&quot;, size = tx * .3, alpha = .6, hjust = 0, lineheight = .8) + annotate(&quot;text&quot;, label = &quot;10% CFR&quot;, x = lim_x + 1000, y = lim_x * .10, color=&quot;grey30&quot;, size = tx * .3, alpha = .6, hjust = 0, lineheight = .8) + annotate(&quot;text&quot;, label = &quot;15% CFR&quot;, x = lim_x + 1000, y = lim_x * .15, color=&quot;grey30&quot;, size = tx * .3, alpha = .6, hjust = 0, lineheight = .8) + scale_colour_manual(values = cols)+ geom_text(data = labs, aes(Cases, Deaths, label = Country), size = tx * .35, hjust = 0, fontface = &quot;bold&quot;) + theme_classic()+ labs(x = &quot;Cases&quot;, y = &quot;Deaths&quot;)+ theme( panel.grid.minor = element_blank(), legend.position = &quot;none&quot;, plot.margin = margin(5,5,5,5,&quot;mm&quot;), axis.text.x = element_text(size = tx), axis.text.y = element_text(size = tx), axis.title.x = element_text(size = tx + 1), axis.title.y = element_text(size = tx + 1) ) # Save ggsave(&quot;Output/Fig_1.jpg&quot;, width = 4, height = 3, dpi = 600) "],["applying-the-guerrilla-analytics-framework-to-your-own-project..html", "4 Applying the Guerrilla analytics framework to your own project.", " 4 Applying the Guerrilla analytics framework to your own project. ## D:/Documenten/Data science/daur2 ## +-- metagenomics_formatief ## | +-- data ## | | +-- fastq ## | | +-- HU_waternet_MOCK2_composition.csv ## | | \\-- README.txt.txt ## | +-- doc ## | \\-- rmd ## | +-- metagenomics_formatief.html ## | +-- metagenomics_formatief.Rmd ## | \\-- README.txt.txt ## +-- metagenomics_reader ## | +-- data ## | | +-- fastq ## | | +-- HU_waternet_MOCK1_composition.csv ## | | \\-- README.txt.txt ## | +-- doc ## | \\-- rmd ## | +-- metagenomics_reader.html ## | +-- metagenomics_reader.Rmd ## | \\-- README.txt.txt ## +-- rna_seq_airway ## | +-- data ## | | +-- airway_sampledata.csv ## | | +-- bam ## | | +-- counts ## | | +-- fastqc ## | | +-- fastqc_ouput ## | | \\-- README.txt.txt ## | +-- doc ## | \\-- rmd ## | +-- README.txt.txt ## | +-- rnaseq_airway_opdracht.html ## | \\-- rnaseq_airway_opdracht.Rmd ## +-- rna_seq_ipsc ## | +-- data ## | | +-- bam ## | | +-- counts ## | | +-- fastqc ## | | +-- fastqc_ouput ## | | +-- ipsc_sampledata.csv ## | | \\-- README.txt.txt ## | +-- doc ## | \\-- rmd ## | +-- README.txt.txt ## | +-- rnaseq_ipsc_opdracht.html ## | \\-- rnaseq_ipsc_opdracht.Rmd ## \\-- rna_seq_onecut ## +-- data ## | +-- bam ## | +-- counts ## | +-- fastqc ## | +-- fastqc_ouput ## | +-- onecut_sampledata_OC2.csv ## | \\-- README.txt.txt ## +-- doc ## \\-- rmd ## +-- README.txt.txt ## +-- rnaseq_onecut.Rmd ## \\-- rnaseq_onecut_opdracht.html Voorbeeldwn van readme bestand: !!RMD!! !!Data!! "],["cv.html", "5 cv", " 5 cv Lisa Kuipers Contact 0612345678 lisa.kuipers26@hotmail.com Werkervaring HEMA Rhenen | 2015  heden Kassa medewerker, horeca medewerker Klanten helpen in de winkel, producten afrekenen en helpen op de klantenservice Klanten bedienen in de horeca Aanvullen van producten in de winkel Opleiding HAVO Rembrandt college Veenendaal | 2012 - 2017 HAVO diploma gehaald met het profiel natuur en gezondheid Hogeschool Utrecht | 2019  Heden HBO Biologie en medisch laboratoriumonderzoek (life science) Minor data science for biology Biomoleculair research specialisatie Talen Nederlands Engels Vaardigheden Microsoft office R Bash Python SQL "],["vrije-ruimte---sql.html", "6 Vrije ruimte - SQL", " 6 Vrije ruimte - SQL Bij het zoeken naar vacatures werden er om veel verschillende c. Het bedrijf waar ik keek en intresse heb in stage lopen (genmab) werd in veel vacatures gevraagd om SQL kennis gevraagd. Er is een les waar er tijd besteed wordt aan het leren van SQL lijkt het mij handig om er wat dieper op in te gaan. Omdat dit nog een beetje een vaag doel is ging ik verder denken hoe ik dit kan toepassen. In een paar vacatures zag ik ook dat er gevraagd werd om mensen die een user interface konden maken. Met het project ga ik shiny leren en kwam op het idee om deze kennis toe te passen voor een product waarin mensen zoek opdrachten kunnen doen en zo informatie uit een database kunnen ophalen. Op deze manier kan ik de de SQL kennis toepassenen ook leren hoe een database met een app samenwerkt. Doel: Een product waarin mensen zoektermen opkunnen geven en een tabel met bijbehorende informatie returnd uit een database. (Globaal) stappen: 1. SQL kennis verbreden 2. Opzet shiny app bedenken 3. Shiny app programmeren 4. Database met shiny app verbinden "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
